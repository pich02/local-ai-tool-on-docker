# local-ai-tool-on-docker

tabbyML, and skyvern with local ollama server

# pull Ollama model

```bash
docker exec -it ollama ollama pull mistral:7b
```

# Get ollama installed models

```bash
curl http://localhost:11434/api/tags
```


